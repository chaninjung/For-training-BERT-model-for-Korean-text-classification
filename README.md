# For-training-BERT-model-for-Korean-text-classification


## 한국어 텍스트 분류를 위한 BERT 모델 학습

## 소개 (Introduction)
이 프로젝트는 한국어 텍스트 분류를 위해 BERT (Bidirectional Encoder Representations from Transformers) 모델을 활용한 것입니다. 주로 자연어 처리 (NLP) 분야에서 텍스트 분류 작업에 사용되는 BERT 모델을 한국어 데이터에 적용하여 성능을 향상시켰습니다.

## 기술 스택 (Tech Stack)
- BERT (한국어 버전)
- TensorFlow
- scikit-learn (평가 및 전처리용)
